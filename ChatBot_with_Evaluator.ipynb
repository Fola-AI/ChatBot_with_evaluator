{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59fd8931-5202-4e3e-9037-d8e7fc698a93",
   "metadata": {},
   "source": [
    "# Chatbot Program\n",
    "\n",
    "#### Chatbot with Evaluator - Hugging Face Deployment Ready\n",
    "- Primary Agent: Google Gemini (via OpenAI API)\n",
    "- Evaluator: Groq Llama 3.3 70B\n",
    "- Fast API-based inference (no local models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8cc2547-3ec6-4bdd-91f5-e40cd449edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from typing import Tuple, Optional\n",
    "import json\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2af12f-e822-496f-8c71-79852b320241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c952710c-d3df-4deb-b6bc-4e987d9cc99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API Key exists and begins AI\n",
      "Groq API Key exists and begins gsk_\n"
     ]
    }
   ],
   "source": [
    "# Check for API keys\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if GOOGLE_API_KEY:\n",
    "    print(f\"Google API Key exists and begins {GOOGLE_API_KEY[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if GROQ_API_KEY:\n",
    "    print(f\"Groq API Key exists and begins {GROQ_API_KEY[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5f3cf9-d24b-46cc-9018-8e025bba2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations\n",
    "AGENT_MODELS = {\n",
    "    # \"Gemini Pro\": {\n",
    "    #     \"model\": \"gemini-pro\",\n",
    "    #     \"description\": \"Google's Gemini Pro model\",\n",
    "    #     \"max_tokens\": 2048\n",
    "    # },\n",
    "    \"Gemini 1.5 flash\": {\n",
    "        \"model\": \"gemini-1.5-flash\", \n",
    "        \"description\": \"Fast Gemini model\",\n",
    "        \"max_tokens\": 2048\n",
    "    }\n",
    "    # \"Gemini 1.5 Pro\": {\n",
    "    #     \"model\": \"gemini-1.5-pro\",\n",
    "    #     \"description\": \"Advanced Gemini model\",\n",
    "    #     \"max_tokens\": 2048\n",
    "    # }\n",
    "}\n",
    "\n",
    "EVALUATOR_MODELS = {\n",
    "    \"Llama 3.3 70B\": {\n",
    "        \"model\": \"llama-3.3-70b-versatile\",\n",
    "        \"description\": \"Groq's Llama 3.3 70B - Fast & Powerful\"\n",
    "    }\n",
    "    # \"Llama 3.1 70B\": {\n",
    "    #     \"model\": \"llama-3.1-70b-versatile\",\n",
    "    #     \"description\": \"Groq's Llama 3.1 70B\"\n",
    "    # },\n",
    "    # \"Mixtral 8x7B\": {\n",
    "    #     \"model\": \"mixtral-8x7b-32768\",\n",
    "    #     \"description\": \"Groq's Mixtral model\"\n",
    "    # }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9918d9-917c-4cfb-9a46-43f5607c6995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# API Client Management Class\n",
    "# ===========================\n",
    "\n",
    "class APIClientManager:\n",
    "    def __init__(self):\n",
    "        self.gemini_client = None\n",
    "        self.groq_client = None\n",
    "        self.errors = []\n",
    "        self.initialize_clients()\n",
    "    \n",
    "    def initialize_clients(self):\n",
    "        \"\"\"Initialize API clients with error handling.\"\"\"\n",
    "        # Get API keys from environment\n",
    "        google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "        \n",
    "        # Initialize Gemini client\n",
    "        if google_api_key:\n",
    "            try:\n",
    "                self.gemini_client = OpenAI(\n",
    "                    api_key=google_api_key,\n",
    "                    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "                )\n",
    "                print(\"‚úÖ Gemini API client initialized\")\n",
    "            except Exception as e:\n",
    "                self.errors.append(f\"Gemini initialization error: {e}\")\n",
    "        else:\n",
    "            self.errors.append(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "        \n",
    "        # Initialize Groq client\n",
    "        if groq_api_key:\n",
    "            try:\n",
    "                self.groq_client = OpenAI(\n",
    "                    api_key=groq_api_key,\n",
    "                    base_url=\"https://api.groq.com/openai/v1\"\n",
    "                )\n",
    "                print(\"‚úÖ Groq API client initialized\")\n",
    "            except Exception as e:\n",
    "                self.errors.append(f\"Groq initialization error: {e}\")\n",
    "        else:\n",
    "            self.errors.append(\"GROQ_API_KEY not found in environment variables\")\n",
    "    \n",
    "    def create_evaluator_prompt(self, user_input: str, agent_response: str) -> str:\n",
    "        \"\"\"Create the evaluation prompt.\"\"\"\n",
    "        evaluator_prompt = (\n",
    "            \"You are an evaluator that decides whether a response to a question is acceptable. \"\n",
    "            \"You are provided with a conversation between a User and an Agent. \"\n",
    "            \"Your task is to decide whether the Agent's latest response is acceptable quality.\\n\\n\"\n",
    "            f\"User Question: {user_input}\\n\\n\"\n",
    "            f\"Agent Response: {agent_response}\\n\\n\"\n",
    "            \"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\\n\\n\"\n",
    "            \"Format your evaluation as follows:\\n\"\n",
    "            \"1. Start with either 'ACCEPTABLE ‚úÖ' or 'UNACCEPTABLE ‚ùå'\\n\"\n",
    "            \"2. Provide a brief quality score (1-10)\\n\"\n",
    "            \"3. List 2-3 specific strengths or issues\\n\"\n",
    "            \"4. Suggest one improvement if needed\"\n",
    "        )\n",
    "        return evaluator_prompt\n",
    "    \n",
    "    def generate_agent_response(\n",
    "        self,\n",
    "        user_input: str,\n",
    "        model_name: str = \"Gemini 1.5 flash\",\n",
    "        temperature: float = 0.7,\n",
    "        max_tokens: int = 500\n",
    "    ) -> Tuple[str, str, float]:\n",
    "        \"\"\"Generate response using Gemini API.\"\"\"\n",
    "        \n",
    "        if not self.gemini_client:\n",
    "            return \"‚ùå Gemini API not initialized. Please set GOOGLE_API_KEY environment variable.\", \"Error\", 0\n",
    "        \n",
    "        try:\n",
    "            model_config = AGENT_MODELS.get(model_name, AGENT_MODELS[\"Gemini 1.5 flash\"])\n",
    "            model_id = model_config[\"model\"]\n",
    "            \n",
    "            # Make API call to Gemini\n",
    "            start_time = time.time()\n",
    "            \n",
    "            response = self.gemini_client.chat.completions.create(\n",
    "                model=model_id,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful AI assistant. Provide clear, accurate, and helpful responses.\"},\n",
    "                    {\"role\": \"user\", \"content\": user_input}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=min(max_tokens, model_config[\"max_tokens\"]),\n",
    "                top_p=0.9\n",
    "            )\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # Extract response\n",
    "            agent_response = response.choices[0].message.content\n",
    "            status = f\"‚úÖ {model_name} responded in {elapsed_time:.2f}s\"\n",
    "            \n",
    "            return agent_response, status, elapsed_time\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"‚ùå Gemini API error: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            \n",
    "            # Check for common errors\n",
    "            if \"API key\" in str(e):\n",
    "                error_msg = \"‚ùå Invalid Google API key. Please check GOOGLE_API_KEY.\"\n",
    "            elif \"quota\" in str(e).lower():\n",
    "                error_msg = \"‚ùå API quota exceeded. Please try again later.\"\n",
    "            elif \"model\" in str(e).lower():\n",
    "                error_msg = f\"‚ùå Model '{model_name}' not available. Try another model.\"\n",
    "                \n",
    "            return error_msg, \"Error\", 0\n",
    "    \n",
    "    def evaluate_response(\n",
    "        self,\n",
    "        user_input: str,\n",
    "        agent_response: str,\n",
    "        evaluator_model: str = \"Llama 3.3 70B\",\n",
    "        temperature: float = 0.3\n",
    "    ) -> Tuple[str, str, float]:\n",
    "        \"\"\"Evaluate the agent's response using Groq API.\"\"\"\n",
    "        \n",
    "        if not self.groq_client:\n",
    "            return \"‚ùå Groq API not initialized. Please set GROQ_API_KEY environment variable.\", \"Error\", 0\n",
    "        \n",
    "        try:\n",
    "            model_config = EVALUATOR_MODELS.get(evaluator_model, EVALUATOR_MODELS[\"Llama 3.3 70B\"])\n",
    "            model_id = model_config[\"model\"]\n",
    "            \n",
    "            # Create evaluation prompt using the class method\n",
    "            eval_prompt = self.create_evaluator_prompt(user_input, agent_response)\n",
    "            \n",
    "            # Make API call to Groq\n",
    "            start_time = time.time()\n",
    "            \n",
    "            response = self.groq_client.chat.completions.create(\n",
    "                model=model_id,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a critical evaluator. Be honest but constructive in your feedback.\"},\n",
    "                    {\"role\": \"user\", \"content\": eval_prompt}\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                max_tokens=300,\n",
    "                top_p=0.9\n",
    "            )\n",
    "            \n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # Extract evaluation\n",
    "            evaluation = response.choices[0].message.content\n",
    "            \n",
    "            # Determine status based on evaluation\n",
    "            if \"ACCEPTABLE\" in evaluation.upper():\n",
    "                status = f\"‚úÖ Evaluation: Acceptable | {evaluator_model} ({elapsed_time:.2f}s)\"\n",
    "            elif \"UNACCEPTABLE\" in evaluation.upper():\n",
    "                status = f\"‚ùå Evaluation: Needs Improvement | {evaluator_model} ({elapsed_time:.2f}s)\"\n",
    "            else:\n",
    "                status = f\"üîç Evaluation Complete | {evaluator_model} ({elapsed_time:.2f}s)\"\n",
    "            \n",
    "            return evaluation, status, elapsed_time\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"‚ùå Groq API error: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            \n",
    "            # Check for common errors\n",
    "            if \"API key\" in str(e):\n",
    "                error_msg = \"‚ùå Invalid Groq API key. Please check GROQ_API_KEY.\"\n",
    "            elif \"rate\" in str(e).lower():\n",
    "                error_msg = \"‚ùå Rate limit exceeded. Please wait a moment and try again.\"\n",
    "            elif \"model\" in str(e).lower():\n",
    "                error_msg = f\"‚ùå Model '{evaluator_model}' not available.\"\n",
    "                \n",
    "            return error_msg, \"Error\", 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1bcabd-6f37-44c7-8de2-d6fe92088f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API client initialized\n",
      "‚úÖ Groq API client initialized\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Initialize Global Client Manager\n",
    "# ===========================\n",
    "\n",
    "api_manager = APIClientManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5d4bee-1d7e-4ac4-b676-3cea5606d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Main Processing Function\n",
    "# ===========================\n",
    "\n",
    "def process_with_evaluation(\n",
    "    user_input: str,\n",
    "    agent_model: str,\n",
    "    evaluator_model: str,\n",
    "    temperature: float,\n",
    "    max_tokens: int,\n",
    "    enable_evaluation: bool\n",
    ") -> Tuple[str, str, str, str]:\n",
    "    \"\"\"Process user input through agent and optionally evaluate.\"\"\"\n",
    "    \n",
    "    if not user_input.strip():\n",
    "        return \"Please enter a message.\", \"\", \"No input provided\", \"\"\n",
    "    \n",
    "    # Step 1: Generate agent response\n",
    "    agent_response, agent_status, agent_time = api_manager.generate_agent_response(\n",
    "        user_input,\n",
    "        agent_model,\n",
    "        temperature,\n",
    "        max_tokens\n",
    "    )\n",
    "    \n",
    "    # Step 2: Evaluate response (if enabled)\n",
    "    if enable_evaluation and \"Error\" not in agent_status:\n",
    "        evaluation, eval_status, eval_time = api_manager.evaluate_response(\n",
    "            user_input,\n",
    "            agent_response,\n",
    "            evaluator_model,\n",
    "            temperature=0.3  # Lower temp for evaluation\n",
    "        )\n",
    "        \n",
    "        # Combine status\n",
    "        total_time = agent_time + eval_time\n",
    "        combined_status = f\"Agent: {agent_model} ({agent_time:.2f}s) | Evaluator: {evaluator_model} ({eval_time:.2f}s) | Total: {total_time:.2f}s\"\n",
    "        \n",
    "        # Format evaluation for better display\n",
    "        if \"ACCEPTABLE\" in evaluation.upper():\n",
    "            eval_summary = \"‚úÖ Response Quality: ACCEPTABLE\"\n",
    "        elif \"UNACCEPTABLE\" in evaluation.upper():\n",
    "            eval_summary = \"‚ùå Response Quality: NEEDS IMPROVEMENT\"\n",
    "        else:\n",
    "            eval_summary = \"üîç Evaluation Complete\"\n",
    "            \n",
    "    else:\n",
    "        evaluation = \"Evaluation disabled or skipped due to error\" if not enable_evaluation else \"Skipped due to agent error\"\n",
    "        eval_summary = \"üîï No evaluation performed\"\n",
    "        combined_status = agent_status\n",
    "    \n",
    "    return agent_response, evaluation, combined_status, eval_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98ddc60a-e033-4b9b-b673-32016de08b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Gradio Interface\n",
    "# ===========================\n",
    "\n",
    "def create_interface():\n",
    "    \"\"\"Create the Gradio interface.\"\"\"\n",
    "    \n",
    "    css = \"\"\"\n",
    "    .gradio-container { max-width: 1400px !important; margin: auto; }\n",
    "    .response-box { background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 12px; border-radius: 8px; }\n",
    "    .evaluation-box { background: #fef3c7; border-left: 4px solid #f59e0b; padding: 12px; border-radius: 8px; }\n",
    "    .status-box { font-family: monospace; font-size: 12px; color: #6b7280; }\n",
    "    .error-box { background: #fee2e2; border-left: 4px solid #ef4444; padding: 12px; border-radius: 8px; }\n",
    "    .success-indicator { color: #10b981; font-weight: bold; }\n",
    "    .warning-indicator { color: #f59e0b; font-weight: bold; }\n",
    "    \"\"\"\n",
    "    \n",
    "    with gr.Blocks(\n",
    "        title=\"AI Chatbot with Cross-Model Evaluator\",\n",
    "        theme=gr.themes.Soft(),\n",
    "        css=css\n",
    "    ) as demo:\n",
    "        \n",
    "        # Header\n",
    "        gr.Markdown(\"\"\"\n",
    "        # ü§ñ AI Chatbot with Cross-Model Evaluator\n",
    "        ### **Agent:** Google Gemini 1.5 flash | **Evaluator:** Groq Llama 3.3 70B\n",
    "        \n",
    "        This system uses two different AI models:\n",
    "        1. **Gemini** generates responses to your questions\n",
    "        2. **Llama 70B** evaluates the quality of those responses\n",
    "        \"\"\")\n",
    "        \n",
    "        # API Status\n",
    "        if api_manager.errors:\n",
    "            with gr.Group():\n",
    "                gr.Markdown(\"### ‚ö†Ô∏è Setup Issues:\")\n",
    "                for error in api_manager.errors:\n",
    "                    gr.Markdown(f\"- {error}\")\n",
    "                gr.Markdown(\"\"\"\n",
    "                **To fix:**\n",
    "                ```bash\n",
    "                export GOOGLE_API_KEY=\"your-google-api-key\"\n",
    "                export GROQ_API_KEY=\"your-groq-api-key\"\n",
    "                ```\n",
    "                Get keys from:\n",
    "                - [Google AI Studio](https://makersuite.google.com/app/apikey)\n",
    "                - [Groq Console](https://console.groq.com/keys)\n",
    "                \"\"\")\n",
    "        else:\n",
    "            gr.Markdown(\"‚úÖ **All API clients initialized successfully**\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            # Left Column - Input Controls\n",
    "            with gr.Column(scale=2):\n",
    "                # Model Selection\n",
    "                with gr.Group():\n",
    "                    gr.Markdown(\"### üéØ Model Selection\")\n",
    "                    agent_model = gr.Dropdown(\n",
    "                        choices=list(AGENT_MODELS.keys()),\n",
    "                        value=\"Gemini 1.5 flash\",\n",
    "                        label=\"Agent Model (Response Generator)\",\n",
    "                        info=\"Google Gemini model for generating responses\"\n",
    "                    )\n",
    "                    \n",
    "                    evaluator_model = gr.Dropdown(\n",
    "                        choices=list(EVALUATOR_MODELS.keys()),\n",
    "                        value=\"Llama 3.3 70B\",\n",
    "                        label=\"Evaluator Model\",\n",
    "                        info=\"Groq model for evaluating response quality\"\n",
    "                    )\n",
    "                \n",
    "                # User Input\n",
    "                user_input = gr.Textbox(\n",
    "                    lines=4,\n",
    "                    placeholder=\"Ask me anything... For example: 'Explain quantum computing in simple terms'\",\n",
    "                    label=\"üí¨ Your Question\",\n",
    "                    max_lines=8\n",
    "                )\n",
    "                \n",
    "                # Settings\n",
    "                with gr.Group():\n",
    "                    gr.Markdown(\"### ‚öôÔ∏è Generation Settings\")\n",
    "                    with gr.Row():\n",
    "                        temperature = gr.Slider(\n",
    "                            minimum=0.1,\n",
    "                            maximum=1.0,\n",
    "                            value=0.7,\n",
    "                            step=0.1,\n",
    "                            label=\"Temperature (Creativity)\",\n",
    "                            info=\"Higher = more creative, Lower = more focused\"\n",
    "                        )\n",
    "                        max_tokens = gr.Slider(\n",
    "                            minimum=50,\n",
    "                            maximum=1000,\n",
    "                            value=500,\n",
    "                            step=50,\n",
    "                            label=\"Max Tokens\",\n",
    "                            info=\"Maximum response length\"\n",
    "                        )\n",
    "                    \n",
    "                    enable_evaluation = gr.Checkbox(\n",
    "                        value=True,\n",
    "                        label=\"üîç Enable Cross-Model Evaluation\",\n",
    "                        info=\"Let Llama 70B evaluate Gemini's response\"\n",
    "                    )\n",
    "                \n",
    "                # Action Buttons\n",
    "                with gr.Row():\n",
    "                    generate_btn = gr.Button(\n",
    "                        \"üöÄ Generate & Evaluate\",\n",
    "                        variant=\"primary\",\n",
    "                        size=\"lg\"\n",
    "                    )\n",
    "                    clear_btn = gr.Button(\"üóëÔ∏è Clear All\", size=\"lg\")\n",
    "            \n",
    "            # Right Column - Outputs\n",
    "            with gr.Column(scale=3):\n",
    "                # Quality Indicator\n",
    "                quality_indicator = gr.Textbox(\n",
    "                    label=\"üìä Response Quality\",\n",
    "                    interactive=False,\n",
    "                    lines=1\n",
    "                )\n",
    "                \n",
    "                # Agent Response\n",
    "                with gr.Group():\n",
    "                    gr.Markdown(\"### ü§ñ Agent Response\")\n",
    "                    agent_output = gr.Textbox(\n",
    "                        lines=10,\n",
    "                        label=\"Gemini's Response\",\n",
    "                        show_copy_button=True,\n",
    "                        interactive=False,\n",
    "                        elem_classes=[\"response-box\"]\n",
    "                    )\n",
    "                \n",
    "                # Evaluation\n",
    "                with gr.Group():\n",
    "                    gr.Markdown(\"### üîç Evaluation Result\")\n",
    "                    evaluation_output = gr.Textbox(\n",
    "                        lines=8,\n",
    "                        label=\"Llama's Evaluation\",\n",
    "                        show_copy_button=True,\n",
    "                        interactive=False,\n",
    "                        elem_classes=[\"evaluation-box\"]\n",
    "                    )\n",
    "                \n",
    "                # Status\n",
    "                status_output = gr.Textbox(\n",
    "                    lines=2,\n",
    "                    label=\"‚è±Ô∏è Performance Metrics\",\n",
    "                    interactive=False,\n",
    "                    elem_classes=[\"status-box\"]\n",
    "                )\n",
    "        \n",
    "        # Examples\n",
    "        with gr.Row():\n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    [\"What is the difference between machine learning and deep learning?\"],\n",
    "                    [\"Write a Python function to calculate the factorial of a number\"],\n",
    "                    [\"Explain the theory of relativity in simple terms\"],\n",
    "                    [\"What are the main causes of climate change?\"],\n",
    "                    [\"How does blockchain technology work?\"],\n",
    "                    [\"What are the benefits and risks of artificial intelligence?\"]\n",
    "                ],\n",
    "                inputs=user_input,\n",
    "                label=\"üí° Example Questions\"\n",
    "            )\n",
    "        \n",
    "        # How It Works\n",
    "        with gr.Accordion(\"‚ÑπÔ∏è How Cross-Model Evaluation Works\", open=False):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### The Two-Stage Process:\n",
    "            \n",
    "            **1. Response Generation (Gemini)**\n",
    "            - Receives your question\n",
    "            - Generates a comprehensive response\n",
    "            - Optimized for helpfulness and accuracy\n",
    "            \n",
    "            **2. Quality Evaluation (Llama 70B)**\n",
    "            - Analyzes the response for:\n",
    "              - Accuracy and completeness\n",
    "              - Clarity and coherence\n",
    "              - Potential issues or biases\n",
    "            - Provides feedback and improvement suggestions\n",
    "            \n",
    "            ### Benefits:\n",
    "            - ‚úÖ **Quality Assurance**: Second model checks for errors\n",
    "            - ‚úÖ **Bias Detection**: Different model perspectives\n",
    "            - ‚úÖ **Improvement Insights**: Specific feedback on responses\n",
    "            - ‚úÖ **Fast Processing**: API-based, no local model loading\n",
    "            \n",
    "            ### API Requirements:\n",
    "            - Google API Key for Gemini (free tier available)\n",
    "            - Groq API Key for Llama (free tier available)\n",
    "            \"\"\")\n",
    "        \n",
    "        # Event Handlers\n",
    "        generate_btn.click(\n",
    "            fn=process_with_evaluation,\n",
    "            inputs=[user_input, agent_model, evaluator_model, temperature, max_tokens, enable_evaluation],\n",
    "            outputs=[agent_output, evaluation_output, status_output, quality_indicator]\n",
    "        )\n",
    "        \n",
    "        clear_btn.click(\n",
    "            fn=lambda: (\"\", \"\", \"\", \"\"),\n",
    "            outputs=[user_input, agent_output, evaluation_output, status_output]\n",
    "        )\n",
    "        \n",
    "        user_input.submit(\n",
    "            fn=process_with_evaluation,\n",
    "            inputs=[user_input, agent_model, evaluator_model, temperature, max_tokens, enable_evaluation],\n",
    "            outputs=[agent_output, evaluation_output, status_output, quality_indicator]\n",
    "        )\n",
    "    \n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62474172-3dca-40ff-a073-5b0871fa0a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ AI Chatbot with Cross-Model Evaluator\n",
      "============================================================\n",
      "‚úÖ Google API Key detected: AIzaSyC3So...\n",
      "‚úÖ Groq API Key detected: gsk_M5dxhz...\n",
      "============================================================\n",
      "üìù Starting Gradio interface...\n",
      "üìå Interface will be available at: http://localhost:7860\n",
      "============================================================\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===========================\n",
    "# Main Execution\n",
    "# ===========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üöÄ AI Chatbot with Cross-Model Evaluator\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check API keys\n",
    "    google_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    groq_key = os.getenv(\"GROQ_API_KEY\")\n",
    "    \n",
    "    if not google_key:\n",
    "        print(\"‚ö†Ô∏è  Warning: GOOGLE_API_KEY not found\")\n",
    "        print(\"   Set it with: export GOOGLE_API_KEY='your-key-here'\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Google API Key detected: {google_key[:10]}...\")\n",
    "    \n",
    "    if not groq_key:\n",
    "        print(\"‚ö†Ô∏è  Warning: GROQ_API_KEY not found\")\n",
    "        print(\"   Set it with: export GROQ_API_KEY='your-key-here'\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Groq API Key detected: {groq_key[:10]}...\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìù Starting Gradio interface...\")\n",
    "    print(\"üìå Interface will be available at: http://localhost:7860\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create and launch interface\n",
    "    demo = create_interface()\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ac4ad0-8b6a-4f2e-9aba-3cfcdf30a35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03710a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
